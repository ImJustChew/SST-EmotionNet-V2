{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "from model import model as sst_model\n",
    "\n",
    "train_specInput_root_path = None\n",
    "train_tempInput_root_path = None\n",
    "train_label_root_path = None\n",
    "\n",
    "test_specInput_root_path = None\n",
    "test_tempInput_root_path = None\n",
    "test_label_root_path = None\n",
    "\n",
    "result_path = None\n",
    "model_save_path = None\n",
    "\n",
    "\n",
    "input_width = None\n",
    "specInput_length = None\n",
    "temInput_length = None\n",
    "\n",
    "depth_spec = None\n",
    "depth_tem = None\n",
    "gr_spec = None\n",
    "gr_tem = None\n",
    "nb_dense_block = None\n",
    "nb_class = None\n",
    "\n",
    "nbEpoch = None\n",
    "batch_size = None\n",
    "lr = None\n",
    "\n",
    "\n",
    "def read_config(config_path):\n",
    "    conf = configparser.ConfigParser()\n",
    "    conf.read(config_path)\n",
    "\n",
    "    global train_specInput_root_path, train_tempInput_root_path, train_label_root_path, test_specInput_root_path, test_tempInput_root_path, test_label_root_path\n",
    "    train_specInput_root_path = conf['path']['train_specInput_root_path']\n",
    "    train_tempInput_root_path = conf['path']['train_tempInput_root_path']\n",
    "    train_label_root_path = conf['path']['train_label_root_path']\n",
    "    test_specInput_root_path = conf['path']['test_specInput_root_path']\n",
    "    test_tempInput_root_path = conf['path']['test_tempInput_root_path']\n",
    "    test_label_root_path = conf['path']['test_label_root_path']\n",
    "\n",
    "    global result_path, model_save_path\n",
    "    result_path = conf['path']['result_path']\n",
    "    model_save_path = conf['path']['model_save_path']\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        os.mkdir(result_path)\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.mkdir(model_save_path)\n",
    "\n",
    "    global input_width, specInput_length, temInput_length, depth_spec, depth_tem, gr_spec, gr_tem, nb_dense_block, nb_class\n",
    "    input_width = int(conf['model']['input_width'])\n",
    "    specInput_length = int(conf['model']['specInput_length'])\n",
    "    temInput_length = int(conf['model']['temInput_length'])\n",
    "    depth_spec = int(conf['model']['depth_spec'])\n",
    "    depth_tem = int(conf['model']['depth_tem'])\n",
    "    gr_spec = int(conf['model']['gr_spec'])\n",
    "    gr_tem = int(conf['model']['gr_tem'])\n",
    "    nb_dense_block = int(conf['model']['nb_dense_block'])\n",
    "    nb_class = int(conf['model']['nb_class'])\n",
    "\n",
    "    global nbEpoch, batch_size, lr\n",
    "    nbEpoch = int(conf['training']['nbEpoch'])\n",
    "    batch_size = int(conf['training']['batch_size'])\n",
    "    lr = float(conf['training']['lr'])\n",
    "\n",
    "read_config('./config/SEED.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 32, 32, 5, 1)\n",
      "(90, 32, 32, 40, 1)\n",
      "(90,)\n",
      "3/3 [==============================] - 1s 31ms/step - loss: 1.4089 - accuracy: 0.5556\n",
      "time taken: 1.1492528915405273\n",
      "\n",
      "test loss 1.4088603258132935\n",
      "accuracy 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "all_result_file = open(os.path.join(result_path, 'all_result.txt'), \"w\")\n",
    "all_result_file.close()\n",
    "\n",
    "# Initialize combined arrays\n",
    "combined_specInput = np.zeros((0, input_width, input_width, specInput_length, 1))\n",
    "combined_tempInput = np.zeros((0, input_width, input_width, temInput_length, 1))\n",
    "combined_label = np.zeros((0))\n",
    "\n",
    "# Loop through subjects and sessions to load and concatenate data\n",
    "for i in range(1, 15 + 1):\n",
    "    for j in range(0, 3, 1):\n",
    "        # combined_specInput = np.concatenate((combined_specInput, np.load(os.path.join(\n",
    "        #     train_specInput_root_path, f\"subject_{i}/section_{j}_data.npy\"))), axis=0)\n",
    "        # combined_tempInput = np.concatenate((combined_tempInput, np.load(os.path.join(\n",
    "        #     train_tempInput_root_path, f\"subject_{i}/section_{j}_data.npy\"))), axis=0)\n",
    "        # combined_label = np.concatenate((combined_label, np.load(os.path.join(\n",
    "        #     train_label_root_path, f\"subject_{i}/section_{j}_label.npy\"))), axis=0)\n",
    "\n",
    "        combined_specInput = np.concatenate((combined_specInput, np.load(os.path.join(\n",
    "            test_specInput_root_path, f\"subject_{i}/section_{j}_data.npy\"))), axis=0)\n",
    "        combined_tempInput = np.concatenate((combined_tempInput, np.load(os.path.join(\n",
    "            test_tempInput_root_path, f\"subject_{i}/section_{j}_data.npy\"))), axis=0)\n",
    "        combined_label = np.concatenate((combined_label, np.load(os.path.join(\n",
    "            test_label_root_path, f\"subject_{i}/section_{j}_label.npy\"))), axis=0)\n",
    "\n",
    "print(combined_specInput.shape)\n",
    "print(combined_tempInput.shape)\n",
    "print(combined_label.shape)\n",
    "\n",
    "# # Shuffle the combined dataset\n",
    "# index = np.arange(combined_specInput.shape[0])\n",
    "# np.random.shuffle(index)\n",
    "\n",
    "# combined_specInput = combined_specInput[index]\n",
    "# combined_tempInput = combined_tempInput[index]\n",
    "# combined_label = combined_label[index]\n",
    "\n",
    "# Convert labels to categorical format\n",
    "combined_label = [x + 1 for x in combined_label]\n",
    "combined_label = to_categorical(combined_label, num_classes=3)\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(model_save_path, f'model.h5'))\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "loss, accuracy = model.evaluate(\n",
    "    [combined_specInput, combined_tempInput], combined_label)\n",
    "print(f'time taken: {time.time() - start_time}')\n",
    "print('\\ntest loss', loss)\n",
    "print('accuracy', accuracy)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|conditions|loss|acc|time_taken|\n",
    "|-|-|-|-|\n",
    "|reduce time to 40s sample, take 40 points |1.414|0.3304|1.6354467868804932|\n",
    "|reduce time to 50s sample, take 40 points |1.4143825769424438|0.34518519043922424|1.7963125705718994|\n",
    "|reduce time to 60s sample, take 40 points |1.414535403251648|0.3392592668533325|1.8803508281707764|\n",
    "|reduce time to 70s sample, take 40 points |1.4145113229751587|0.3466666638851166|1.7162754535675049|\n",
    "|reduce time to 90s sample, take 40 points |1.414594054222107|0.3377777636051178|1.699704885482788|\n",
    "|reduce time to 110s sample, take 40 points |1.4146376848220825|0.3318518400192261|1.9813542366027832|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
